Homework 08
===========

--- Activity 1 ---
1. entry_create first allocates memory for the Entry using malloc. There are two more statements that allocated memory using strdup: One to copy the key, and the other to copy the value (only if type is set to STRING). entry_delete does the same thing in reverse order: it frees value if it's a STRING, frees the key, then finally frees the Entry pointer. I handled the recursive flag for entry_delete by having a recursive call to delete e->next just before freeing the Entry e (as long as e->next was not NULL).

2. In map_create, memory for the map struct is allocated using malloc, and then memory for the buckets is allocated using calloc, which clears everything to 0. This way, the "next" field of all of the top-level "dummy" Entries is already NULL without any extra assignment or creation. 
map_delete has three tasks:
    1) free all of the Entries that have been added - it does this by looping through all the dummy nodes and calling entry_delete with recursion enabled on their "next" fields (entry_delete quits early if the Entry to delete is NULL).
    2) free the buckets array - this is simple, just call free(m->buckets)
    and 3) free the map struct - also simple: free(m).

3. map_resize is called when the average number of entries per bucket is greater than the specified load factor (i.e. m->size/m->capacity > m->load_factor). To grow the map it does the following:
    1) Allocate a new block of memory (newBuckets) that is double the size of the previous.
    2) Re-hash all of the entries in the list and update their pointers to put them in the proper locations in newBuckets
    3) Free the old buckets array
    4) Update the "buckets" field of the map to point to the new memory (newBuckets)
    5) Update the "capacity" field of the map to reflect the new doubled size

4. map_insert has three sub-tasks that it does:
    1) Check if the map needs resizing (load > load_factor), and resize if it does
    2) Search to see if an Entry with that key exists in the map, and update its value if so
    3) If no existing Entry, insert a new Entry in the proper location

Amortized, both the time and space complexities of this algorithm is O(1). Resizing is a more expensive operation (O(n)), but that happens relatively rarely. The most expensive opearation that happens each time is searching the map for an existing Entry: it has to search linearly through all of the entries in the relevant bucket for one with a matching key. This scales with the load_factor, and so is still constant time (O(1)).

5. map_search works by hashing the provided key, and searching the bin that hash resolves to for an Entry with a matching key. It does a linear search through the linked list until it either finds and returns a matching Entry or NULL. The space complexity is O(1) - it only uses one extra Entry pointer to iterate, regardless of input size. Time complexity is O(1) as well, even though it searches linearly through the list. The average list length is equal to load_factor, so even as input size grows, it stays the same thanks to the map resizing.

6. map_remove works very similarly to map_search. It hashes the key, and searches the relevant bucket for an Entry matching it. If it finds a matching Entry, it deletes it using entry_delete, but first updates the "next" field of the previous Entry to point to the Entry after it (or NULL), so that the chain is not broken.
    For the same reasons as map_search, map_delete has both a space and time complexity of O(1). The complexity of its most complex portion scales with load_factor, which is a constant with respect to the input size.

--- Activity 2 ---
Note - see BENCHMARK.md for the table generated by benchmark.py

1. Holding the number of items constant, the amount of memory used strictly decreases as the load factor increases, but the amount of time varies a bit more, decreasing for the first few, then increasing as the factors get bigger. It makes sense that the memory would strictly decrease - the load factor represents how long the map will wait until it resizes, so bigger values let it store more data in a smaller amount of allocated buckets. However, with very small load factors it spends a lot of time resizing, and with very large factors it takes a longer time to search through the many entries in each bucket, so it makes sense for it to be not simply linear.

2. The hash table does extremely well when it comes to random access. If the questions that you need to answer with your data structure are all about membership and data lookup, it's a very good choice -- the hashing function makes it very fast to find or search for a specific known item or value. However, it doesn't store any relationship between the data. If you wanted to find "the next largest" value, you'd have to search the whole table and remember the next largest. Hash tables perform best as sets.
Treaps, on the other hands, work better as priority queues. Searching is still rather fast, but they are best for applications where you need sorted data, or need to quickly find the next biggest, or all entries less than a given one, etc.

If I had to use one underlying data structure for a map, I would choose a hash table. The O(1) access and lookup is very appealing, and while you do have to resize the table sometimes, you don't have to do as much rearranging every operation to keep it running well (like you do e.g. for balancing a treap).
